{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Language Models and Word Embedding Exercise.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4sVGoDTdp05k"
      },
      "outputs": [],
      "source": [
        "# Adapted from Chapter 12 of LDL book"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
        "import tensorflow as tf\n",
        "import logging\n",
        "tf.get_logger().setLevel(logging.ERROR)\n",
        "\n",
        "EPOCHS = 32\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "INPUT_FILE_NAME = 'data/frankenstein.txt'"
      ],
      "metadata": {
        "id": "rA-P1aXZqHgo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data is from here: https://www.gutenberg.org/files/84/84-0.txt"
      ],
      "metadata": {
        "id": "AepAYHNMrAHh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "WINDOW_LENGTH = 40\n",
        "WINDOW_STEP = 3\n",
        "PREDICT_LENGTH = 3\n",
        "MAX_WORDS = 10000\n",
        "EMBEDDING_WIDTH = 100"
      ],
      "metadata": {
        "id": "hApriGEsrHQM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Open and read file\n",
        "file = open(INPUT_FILE_NAME, 'r', encoding='utf-8')\n",
        "text = file.read()\n",
        "file.close()"
      ],
      "metadata": {
        "id": "UE2833jCrSbB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make lower case and split into individual words\n",
        "text = text_to_word_sequence(text)"
      ],
      "metadata": {
        "id": "KKpwCm22sFxu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text[0:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9GKxXjFsGcy",
        "outputId": "d3dd2a59-2229-4ef8-d891-8dae5fcd4eac"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\ufeffthe',\n",
              " 'project',\n",
              " 'gutenberg',\n",
              " 'ebook',\n",
              " 'of',\n",
              " 'frankenstein',\n",
              " 'by',\n",
              " 'mary',\n",
              " 'wollstonecraft',\n",
              " 'godwin']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create training examples.\n",
        "fragments = []\n",
        "targets = []\n",
        "for i in range(0, len(text) - WINDOW_LENGTH, WINDOW_STEP):\n",
        "  fragments.append(text[i: i + WINDOW_LENGTH])\n",
        "  targets.append(text[i + WINDOW_LENGTH])"
      ],
      "metadata": {
        "id": "f7EQmeP2sLaE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting training input to word indices and then output to one-hot encoding\n",
        "tokenizer = Tokenizer(num_words = MAX_WORDS, oov_token='UNK')\n",
        "tokenizer.fit_on_texts(text)"
      ],
      "metadata": {
        "id": "17yi5vR-sa82"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CuIwnaAQsqdU",
        "outputId": "f31efe8c-b4b1-4474-e0f1-bb86b1c1ff2a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "keras_preprocessing.text.Tokenizer"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fragments_indexed = tokenizer.texts_to_sequences(fragments)"
      ],
      "metadata": {
        "id": "tKzAlSFisr-3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "targets_indexed = tokenizer.texts_to_sequences(targets)"
      ],
      "metadata": {
        "id": "iTYRGku2svRG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fragments[0:1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVEVl117syd5",
        "outputId": "da81b246-59af-431d-9b60-26841bdadccf"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['\\ufeffthe',\n",
              "  'project',\n",
              "  'gutenberg',\n",
              "  'ebook',\n",
              "  'of',\n",
              "  'frankenstein',\n",
              "  'by',\n",
              "  'mary',\n",
              "  'wollstonecraft',\n",
              "  'godwin',\n",
              "  'shelley',\n",
              "  'this',\n",
              "  'ebook',\n",
              "  'is',\n",
              "  'for',\n",
              "  'the',\n",
              "  'use',\n",
              "  'of',\n",
              "  'anyone',\n",
              "  'anywhere',\n",
              "  'in',\n",
              "  'the',\n",
              "  'united',\n",
              "  'states',\n",
              "  'and',\n",
              "  'most',\n",
              "  'other',\n",
              "  'parts',\n",
              "  'of',\n",
              "  'the',\n",
              "  'world',\n",
              "  'at',\n",
              "  'no',\n",
              "  'cost',\n",
              "  'and',\n",
              "  'with',\n",
              "  'almost',\n",
              "  'no',\n",
              "  'restrictions',\n",
              "  'whatsoever']]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fragments_indexed[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZ_BCPTXszG2",
        "outputId": "cbe1135a-4852-49ab-8901-07110edea74b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4294,\n",
              " 100,\n",
              " 88,\n",
              " 687,\n",
              " 5,\n",
              " 305,\n",
              " 24,\n",
              " 2380,\n",
              " 2381,\n",
              " 2382,\n",
              " 2383,\n",
              " 26,\n",
              " 687,\n",
              " 32,\n",
              " 23,\n",
              " 2,\n",
              " 387,\n",
              " 5,\n",
              " 982,\n",
              " 3074,\n",
              " 9,\n",
              " 2,\n",
              " 433,\n",
              " 458,\n",
              " 3,\n",
              " 92,\n",
              " 96,\n",
              " 1633,\n",
              " 5,\n",
              " 2,\n",
              " 182,\n",
              " 31,\n",
              " 53,\n",
              " 2384,\n",
              " 3,\n",
              " 13,\n",
              " 203,\n",
              " 53,\n",
              " 3075,\n",
              " 2385]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targets[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "560I5APMs4RJ",
        "outputId": "6930abca-ee47-4a57-ade6-77ecd21fcd56"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'you'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targets_indexed[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cucskpe4s6QE",
        "outputId": "d292dcac-d3f8-46b0-f616-aa4c0f6ef6f9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[16]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to appropriate input and output formats\n",
        "X = np.array(fragments_indexed, dtype=np.int)\n",
        "y = np.zeros((len(targets_indexed), MAX_WORDS))\n",
        "\n",
        "for i, target_index in enumerate(targets_indexed):\n",
        "  y[i, target_index] = 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWhCS1bYs7jB",
        "outputId": "c76559fb-7e7c-4109-8cbb-bc7d86cd7bf3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54kPj56_tN7v",
        "outputId": "f7ed518b-1173-4cfe-8954-2233d51e367a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, build and train the model!\n",
        "training_model = Sequential()\n",
        "training_model.add(Embedding(output_dim=EMBEDDING_WIDTH, input_dim=MAX_WORDS, mask_zero=True, input_length=None))\n",
        "training_model.add(LSTM(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2))\n",
        "training_model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "training_model.add(Dense(128, activation='relu'))\n",
        "training_model.add(Dense(MAX_WORDS, activation='softmax'))"
      ],
      "metadata": {
        "id": "d4RpiRyltOgS"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "metadata": {
        "id": "GjR1KZxotnIu"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwKnanRBtqrT",
        "outputId": "47951d12-ac82-4db0-a255-ad58bda7b913"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 100)         1000000   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, None, 128)         117248    \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 128)               131584    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10000)             1290000   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,555,344\n",
            "Trainable params: 2,555,344\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = training_model.fit(X, y, validation_split=0.05, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=2, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zK5L2XE_trx9",
        "outputId": "61e1158a-076a-4ebd-9ca8-2108a671d62b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/32\n",
            "98/98 - 61s - loss: 7.1969 - val_loss: 7.7315 - 61s/epoch - 627ms/step\n",
            "Epoch 2/32\n",
            "98/98 - 46s - loss: 6.4788 - val_loss: 7.8823 - 46s/epoch - 468ms/step\n",
            "Epoch 3/32\n",
            "98/98 - 38s - loss: 6.3339 - val_loss: 8.1629 - 38s/epoch - 387ms/step\n",
            "Epoch 4/32\n",
            "98/98 - 40s - loss: 6.2233 - val_loss: 8.3384 - 40s/epoch - 408ms/step\n",
            "Epoch 5/32\n",
            "98/98 - 42s - loss: 6.0975 - val_loss: 8.3084 - 42s/epoch - 432ms/step\n",
            "Epoch 6/32\n",
            "98/98 - 46s - loss: 5.9743 - val_loss: 8.3917 - 46s/epoch - 467ms/step\n",
            "Epoch 7/32\n",
            "98/98 - 41s - loss: 5.8852 - val_loss: 8.4861 - 41s/epoch - 418ms/step\n",
            "Epoch 8/32\n",
            "98/98 - 40s - loss: 5.8399 - val_loss: 8.3894 - 40s/epoch - 409ms/step\n",
            "Epoch 9/32\n",
            "98/98 - 45s - loss: 5.7699 - val_loss: 8.5485 - 45s/epoch - 463ms/step\n",
            "Epoch 10/32\n",
            "98/98 - 41s - loss: 5.6885 - val_loss: 8.6191 - 41s/epoch - 422ms/step\n",
            "Epoch 11/32\n",
            "98/98 - 44s - loss: 5.6368 - val_loss: 8.5958 - 44s/epoch - 451ms/step\n",
            "Epoch 12/32\n",
            "98/98 - 44s - loss: 5.5637 - val_loss: 8.6279 - 44s/epoch - 446ms/step\n",
            "Epoch 13/32\n",
            "98/98 - 44s - loss: 5.5020 - val_loss: 8.8256 - 44s/epoch - 453ms/step\n",
            "Epoch 14/32\n",
            "98/98 - 47s - loss: 5.4412 - val_loss: 8.8025 - 47s/epoch - 478ms/step\n",
            "Epoch 15/32\n",
            "98/98 - 39s - loss: 5.3889 - val_loss: 9.0649 - 39s/epoch - 395ms/step\n",
            "Epoch 16/32\n",
            "98/98 - 38s - loss: 5.3359 - val_loss: 9.0727 - 38s/epoch - 391ms/step\n",
            "Epoch 17/32\n",
            "98/98 - 38s - loss: 5.2854 - val_loss: 9.2133 - 38s/epoch - 391ms/step\n",
            "Epoch 18/32\n",
            "98/98 - 37s - loss: 5.2375 - val_loss: 9.3850 - 37s/epoch - 377ms/step\n",
            "Epoch 19/32\n",
            "98/98 - 38s - loss: 5.1852 - val_loss: 9.4853 - 38s/epoch - 390ms/step\n",
            "Epoch 20/32\n",
            "98/98 - 37s - loss: 5.1363 - val_loss: 9.6196 - 37s/epoch - 380ms/step\n",
            "Epoch 21/32\n",
            "98/98 - 36s - loss: 5.0987 - val_loss: 9.7817 - 36s/epoch - 372ms/step\n",
            "Epoch 22/32\n",
            "98/98 - 38s - loss: 5.0572 - val_loss: 9.8684 - 38s/epoch - 386ms/step\n",
            "Epoch 23/32\n",
            "98/98 - 37s - loss: 4.9998 - val_loss: 9.9148 - 37s/epoch - 379ms/step\n",
            "Epoch 24/32\n",
            "98/98 - 38s - loss: 4.9453 - val_loss: 10.0731 - 38s/epoch - 389ms/step\n",
            "Epoch 25/32\n",
            "98/98 - 37s - loss: 4.9059 - val_loss: 10.2424 - 37s/epoch - 379ms/step\n",
            "Epoch 26/32\n",
            "98/98 - 39s - loss: 4.8721 - val_loss: 10.1132 - 39s/epoch - 396ms/step\n",
            "Epoch 27/32\n",
            "98/98 - 38s - loss: 5.0366 - val_loss: 9.9152 - 38s/epoch - 384ms/step\n",
            "Epoch 28/32\n",
            "98/98 - 38s - loss: 4.9277 - val_loss: 10.1016 - 38s/epoch - 390ms/step\n",
            "Epoch 29/32\n",
            "98/98 - 38s - loss: 4.8581 - val_loss: 10.4143 - 38s/epoch - 388ms/step\n",
            "Epoch 30/32\n",
            "98/98 - 37s - loss: 4.8014 - val_loss: 10.6173 - 37s/epoch - 378ms/step\n",
            "Epoch 31/32\n",
            "98/98 - 38s - loss: 4.7467 - val_loss: 10.7982 - 38s/epoch - 386ms/step\n",
            "Epoch 32/32\n",
            "98/98 - 37s - loss: 4.6982 - val_loss: 11.0170 - 37s/epoch - 373ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a stateful model used for prediction\n",
        "inference_model = Sequential()\n",
        "inference_model.add(Embedding(output_dim=EMBEDDING_WIDTH, input_dim=MAX_WORDS, mask_zero=True, batch_input_shape=(1,1)))\n",
        "inference_model.add(LSTM(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2, stateful=True))\n",
        "inference_model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2, stateful=True))\n",
        "inference_model.add(Dense(128, activation='relu'))\n",
        "inference_model.add(Dense(MAX_WORDS, activation='softmax'))\n",
        "weights = training_model.get_weights()\n",
        "inference_model.set_weights(weights)"
      ],
      "metadata": {
        "id": "nME_Fxz8t1-f"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feeding the predicted output back as input with one word each time\n",
        "first_words = ['i', 'saw']\n",
        "first_words_indexed = tokenizer.texts_to_sequences(first_words)\n",
        "\n",
        "inference_model.reset_states() # this is important!\n",
        "predicted_string = ''\n",
        "\n",
        "# Feed initial words to the model\n",
        "for i, word_index in enumerate(first_words_indexed):\n",
        "  x = np.zeros((1,1), dtype=np.int)\n",
        "  x[0][0] = word_index[0]\n",
        "  predicted_string += first_words[i]\n",
        "  predicted_string += ' '\n",
        "  y_predict = inference_model.predict(x, verbose=0)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baveG7hOu8Zk",
        "outputId": "9e7a672e-934b-488f-b19b-209270ee530e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict PREDICT_LENGTH words\n",
        "for i in range(PREDICT_LENGTH):\n",
        "  new_word_index = np.argmax(y_predict)\n",
        "  word = tokenizer.sequences_to_texts([[new_word_index]])\n",
        "  x[0][0] = new_word_index\n",
        "  predicted_string += word[0]\n",
        "  predicted_string += ' '\n",
        "  y_predict = inference_model.predict(x, verbose=0)[0]\n",
        "print(predicted_string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc4_SrbhvmFy",
        "outputId": "caf2c5a8-b927-472c-b724-0ea891fb3f9b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i saw i had been \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Explore embedding similarities\n",
        "embeddings = training_model.layers[0].get_weights()[0]\n",
        "lookup_words = ['the', 'saw', 'see', 'of', 'and', 'monster', 'frankenstein', 'read', 'eat']"
      ],
      "metadata": {
        "id": "vf4TwRYUwFDZ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for lookup_word in lookup_words:\n",
        "  lookup_word_indexed = tokenizer.texts_to_sequences([lookup_word])\n",
        "  print('words close to: ', lookup_word)\n",
        "  lookup_embedding = embeddings[lookup_word_indexed[0]]\n",
        "  word_indices = {}\n",
        "  # Calculate distances.\n",
        "  for i, embedding in enumerate(embeddings):\n",
        "    distance = np.linalg.norm(embedding - lookup_embedding)\n",
        "    word_indices[distance] = i\n",
        "\n",
        "  for distance in sorted(word_indices.keys())[:5]:\n",
        "    word_index = word_indices[distance]\n",
        "    word = tokenizer.sequences_to_texts([[word_index]])[0]\n",
        "    print(word + ': ', distance)\n",
        "  print(' ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6j5UTJUwSAM",
        "outputId": "2af4ccad-afc9-4102-f7d2-8148ab00e00d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "words close to:  the\n",
            "the:  0.0\n",
            "“the:  1.2943733\n",
            "insensible:  1.4316504\n",
            "adam’s:  1.4418707\n",
            "perpendicular:  1.447996\n",
            " \n",
            "words close to:  saw\n",
            "saw:  0.0\n",
            "if:  0.5204753\n",
            "asked:  0.5256026\n",
            "incomplete:  0.52671164\n",
            "howlings:  0.526892\n",
            " \n",
            "words close to:  see\n",
            "see:  0.0\n",
            "UNK:  0.44503567\n",
            "copied:  0.49491465\n",
            "UNK:  0.49917632\n",
            "UNK:  0.5021899\n",
            " \n",
            "words close to:  of\n",
            "of:  0.0\n",
            "UNK:  0.36455932\n",
            "UNK:  0.37026545\n",
            "accepting:  0.37322485\n",
            "UNK:  0.37345725\n",
            " \n",
            "words close to:  and\n",
            "and:  0.0\n",
            "not:  0.39689806\n",
            "UNK:  0.43762556\n",
            "UNK:  0.4407267\n",
            "UNK:  0.4459028\n",
            " \n",
            "words close to:  monster\n",
            "monster:  0.0\n",
            "UNK:  0.39784324\n",
            "UNK:  0.41628847\n",
            "UNK:  0.42031655\n",
            "UNK:  0.42256182\n",
            " \n",
            "words close to:  frankenstein\n",
            "frankenstein:  0.0\n",
            "to:  0.49774316\n",
            "is:  0.5118301\n",
            "not:  0.5363105\n",
            "UNK:  0.55768377\n",
            " \n",
            "words close to:  read\n",
            "read:  0.0\n",
            "jumped:  0.49513093\n",
            "what:  0.5026335\n",
            "misery:  0.50475585\n",
            "inferiors:  0.5058931\n",
            " \n",
            "words close to:  eat\n",
            "eat:  0.0\n",
            "chaise:  0.49543878\n",
            "irresistible:  0.50338644\n",
            "pure:  0.52177197\n",
            "adrift:  0.5284761\n",
            " \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pi00ogLiw3mr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}