{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Autocompletion LSTM and Beam Search Algorithm.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rYxS5gzC4DIz"
      },
      "outputs": [],
      "source": [
        "# Adapted from Chapter 11 in LDL"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LSTM\n",
        "import tensorflow as tf\n",
        "import logging\n",
        "tf.get_logger().setLevel(logging.ERROR)"
      ],
      "metadata": {
        "id": "fj2zjU-u4Wt0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# parameters\n",
        "EPOCHS = 5 # cut down the batch size due to a long runtime\n",
        "BATCH_SIZE = 256\n",
        "INPUT_FILE_NAME = 'data/frankenstein.txt'\n",
        "WINDOW_LENGTH = 40\n",
        "WINDOW_STEP = 3\n",
        "BEAM_SIZE = 8\n",
        "NUM_LETTERS = 11\n",
        "MAX_LENGTH = 50"
      ],
      "metadata": {
        "id": "_5KRWuBM4y6x"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the input file\n",
        "file = open(INPUT_FILE_NAME, 'r', encoding='utf-8')\n",
        "text = file.read()\n",
        "file.close()"
      ],
      "metadata": {
        "id": "raAKru5r47sX"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make lowercase, remove newline as well as extra spaces\n",
        "text = text.lower()\n",
        "text = text.replace('\\n', ' ')\n",
        "text = text.replace(' ', '')"
      ],
      "metadata": {
        "id": "jykBqXll5FOh"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode characters as indices\n",
        "unique_chars = list(set(text))\n",
        "char_to_index = dict((ch, index) for index, ch in enumerate(unique_chars))\n",
        "index_to_char = dict((index, ch) for index, ch in enumerate(unique_chars))\n",
        "encoding_width = len(char_to_index)"
      ],
      "metadata": {
        "id": "4djyeLy05V8K"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create training examples\n",
        "fragments = []\n",
        "targets = []\n",
        "for i in range(0, len(text) - WINDOW_LENGTH, WINDOW_STEP):\n",
        "  fragments.append(text[i: i + WINDOW_LENGTH])\n",
        "  targets.append(text[i + WINDOW_LENGTH])"
      ],
      "metadata": {
        "id": "Zi6Bu7kL5lfH"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting to one-hot encoded training data\n",
        "X = np.zeros((len(fragments), WINDOW_LENGTH, encoding_width))\n",
        "y = np.zeros((len(fragments), encoding_width))\n",
        "\n",
        "for i, fragment in enumerate(fragments):\n",
        "  for j, char in enumerate(fragment):\n",
        "    X[i, j, char_to_index[char]] = 1\n",
        "  target_char = targets[i]\n",
        "  y[i, char_to_index[target_char]] = 1"
      ],
      "metadata": {
        "id": "pWWvNADx5zmc"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "targets[0:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6q6pKKG6Hg5",
        "outputId": "8d3284fa-0823-4fa7-9010-2576c69e00a8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['b', 'a', 'w', 'l', 'o']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fragments[0:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEgiKgLd6J17",
        "outputId": "1b155a49-c4b2-485b-a58d-cb1a7c3ddc9d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\ufefftheprojectgutenbergebookoffrankenstein,',\n",
              " 'eprojectgutenbergebookoffrankenstein,bym',\n",
              " 'ojectgutenbergebookoffrankenstein,bymary',\n",
              " 'ctgutenbergebookoffrankenstein,bymarywol',\n",
              " 'utenbergebookoffrankenstein,bymarywollst']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build and train model\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2, input_shape=(None, encoding_width)))\n",
        "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(encoding_width, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "metadata": {
        "id": "oiOLkXgH6SAM"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPrGPQ6L6rcJ",
        "outputId": "bb63779e-3639-4681-81e0-a73b014455d4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, None, 128)         99840     \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 128)               131584    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 66)                8514      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 239,938\n",
            "Trainable params: 239,938\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X, y, validation_split=0.05, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=2, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmOM5lSz6sRN",
        "outputId": "d4478f6d-5e8c-429e-daa3-8b5058b1b1b2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "445/445 - 153s - loss: 2.9710 - val_loss: 2.8912 - 153s/epoch - 344ms/step\n",
            "Epoch 2/5\n",
            "445/445 - 146s - loss: 2.7136 - val_loss: 2.8171 - 146s/epoch - 329ms/step\n",
            "Epoch 3/5\n",
            "445/445 - 149s - loss: 2.6458 - val_loss: 2.7678 - 149s/epoch - 335ms/step\n",
            "Epoch 4/5\n",
            "445/445 - 149s - loss: 2.5972 - val_loss: 2.7368 - 149s/epoch - 335ms/step\n",
            "Epoch 5/5\n",
            "445/445 - 149s - loss: 2.5555 - val_loss: 2.6942 - 149s/epoch - 334ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create initial single beam represented by triplet as (prob, string, one-hot encoded string)\n",
        "letters = 'the body '\n",
        "one_hots = []\n",
        "\n",
        "for i, char in enumerate(letters):\n",
        "  x = np.zeros(encoding_width)\n",
        "  # x[char_to_index[char]] = 1 # for some reason, this line errors\n",
        "  one_hots.append(x)\n",
        "beams = [(np.log(1.0), letters, one_hots)]"
      ],
      "metadata": {
        "id": "JjppR30T6ywD"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict NUM_LETTERS into the future\n",
        "for i in range(NUM_LETTERS):\n",
        "  minibatch_list = []\n",
        "  # Create minibatch from one-hot encodings, and predict the result\n",
        "  for triple in beams:\n",
        "    minibatch_list.append(triple[2])\n",
        "    minibatch = np.array(minibatch_list)\n",
        "    y_predict = model.predict(minibatch, verbose=0)\n",
        "    new_beams = []\n",
        "    for j, softmax_vec in enumerate(y_predict):\n",
        "      triple = beams[j]\n",
        "      # Create BEAM_SIZE new beams from each existing beam\n",
        "      for k in range(BEAM_SIZE):\n",
        "        char_index = np.argmax(softmax_vec)\n",
        "        new_prob = triple[0] + np.log(softmax_vec[char_index])\n",
        "        new_letters = triple[1] + index_to_char[char_index]\n",
        "        x = np.zeros(encoding_width)\n",
        "        x[char_index] = 1\n",
        "        new_one_hots = triple[2].copy()\n",
        "        new_one_hots.append(x)\n",
        "        new_beams.append((new_prob, new_letters, new_one_hots))\n",
        "        softmax_vec[char_index] = 0\n",
        "  new_beams.sort(key=lambda tup: tup[0], reverse=True)\n",
        "  beams = new_beams[0:BEAM_SIZE]\n",
        "for item in beams:\n",
        "  print(item[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbK0ya-47I-K",
        "outputId": "5d4e17ff-46a0-490b-bf79-feacaa6bc545"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the body thesthesthe\n",
            "the body andandandin\n",
            "the body theandandin\n",
            "the body thestheande\n",
            "the body thesthestha\n",
            "the body andandandan\n",
            "the body thestheandi\n",
            "the body thestheanda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ox_A4j8x8WDL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}